[{"body":"Background and Goal Today, data-based projects have a critical impact on any business. The amount of historical information available, the different data sources that enrich this information, and the ability to compute and execute advanced techniques, are some of the indicators that demonstrate why this branch of technology has become one of the main actors in the stage. For approximately four years, the evolution in terms of technological framework and algorithms has been overwhelming. A lot of new technological approaches and improvements in the state-of-the-art solutions and methods applied have helped to push this field to be more controlled, established and mature. Much of the responsibility is held by software engineering, where methodologies and patterns have been adopted when designing artificial intelligence solutions.\nHowever, in order to achieve total technological maturity, there are still many gaps in the methodologies inherited from software engineering that need to be filled in. Although total technological maturity is very ambitious, there are improvements and changes that can be adopted in the medium term. With that goal in mind, the Science Toolkit has been developed following this idea of ​moving to the next level of maturity.\nThe Science Toolkit goal can be defined in one sentence as:\n“To offer a standard environment that covers the technological and methodological needs of a data team in an artificial intelligence project.”\nWhat is the Science Toolkit? As mentioned in the previous section, the Science Toolkit is a solution that offers a standard environment to cover the technological and methodological needs of a data team working in any artificial intelligence project, allowing the data scientists to focus on gaining value and new insights from the data.\nRegarding the technological needs, the science Toolkit is composed of a suite with the latest frameworks and libraries in the same environment, as well as, its own engineering approaches such as data versioning, model versioning, continuous integration, dashboards for data visualization, etc. In terms of the methodology, the Science Toolkit is designed to develop experiments guided by hypotheses, so that the control is greater and the collaboration between team members is easier and more effective.\nScience Toolkit Workflow Applying the proper methodology in artificial intelligence projects is a challenging task. There is a lot of literature covering the main phases and levels of a data project. Nowadays the definition of the right workflow to face real data projects is pretty similar in the main organizations working in this area. The Science Toolkit is designed to provide the right tools and the right workflow to help A.I. researchers and practitioners to work applying these methodology standards. For any data project, the first step would be to design a set of initial hypotheses that will guide the work. Following the hypotheses definition, an exploratory data analysis is performed in some cases together with the development of some preliminary models, to gain data knowledge and starting to get some insights regarding the hypotheses.\nWith this objective in mind, the Science Toolkit offers a data-studio based on open source technologies to perform these tasks easily. It is important to take into account that along the entire project, a volume to persist temporary data or artifacts is necessary for good project development.\nOnce the hypotheses are proven and the data analysis returns a promising output, it is advisable to adopt software engineer methodologies or patterns to develop the solution in the correct way. Some good practices such as ATDD, code decoupling or unit tests are examples that can be useful to control that the project evolves in the right path. At this point, a code editor is mandatory to facilitate development. Of course, all of the generated code is maintained through some code version technology (i.e: git).\nAnother useful adoption is continuous integration and execution. Having the experiments totally automated is a win for the project because it allows testing of different configurations for the executions in favor of having the best possible solution. Some of the benefits of applying this approach are automated execution, saved metrics, charts generation or artifacts serialization.\nAs it is important to not lose sight of the useful information that we need to store related to the experiments, a solution for managing this information as useful metrics is needed as well as a database to store it.\nLast but not least, a dashboard is mandatory to support the analysis during the exploratory data analysis phase and for checking the results of the experiments executed.\nThe Science Toolkit covers with open source technologies all the needs for the different phases highlighted in the previous paragraphs. The aim of this is to provide a suite of tools and technological frameworks to work in data projects, as well as, the right workflow and methodology to help artificial intelligence researchers and practitioners to obtain the maximum value from each phase of the project.\n","excerpt":"Background and Goal Today, data-based projects have a critical impact on any business. The amount of …","ref":"/science-toolkit/docs/overview/","title":"Overview"},{"body":"Documentation homepage.\n","excerpt":"Documentation homepage.","ref":"/science-toolkit/docs/","title":"Documentation"},{"body":"Pre-requisites In order to install Science Toolkit needs the following tools:\n Helm version 3. + info (works also with v2) A Kubernetes cluster (tested only with 1.15.4) + info  You can also use a local cluster like minikube.    Add helm dependencies repos $ helm repo add stable https://kubernetes-charts.storage.googleapis.com $ helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/ $ helm repo add science-toolkit https://intelygenz.github.io/science-toolkit/helm-chart/ $ helm repo update Setting up chart values Make a copy of sample-values.yaml and change what you need to deploy Science Toolkit on top of a Minikube local environment.\nBasically you need to set some credentials for different components. Only change your storage class name if your cluster have something different from standard.\nInstallation $ helm upgrade \\  --wait \\  --install science-toolkit \\  --namespace science-toolkit \\  --values values.yaml \\  --timeout 5m \\  science-toolkit/science-toolkit Domain Setup If you are deploying Science Toolkit in a remote cluster you need setup a DNS subdomain pointint to the ip address where your ingress controller is listening, and set this domain in the values.yaml file before deploy it.\n","excerpt":"Pre-requisites In order to install Science Toolkit needs the following tools:\n Helm version 3. + …","ref":"/science-toolkit/docs/getting-started/","title":"Getting Started"},{"body":"Gitea Gitea is an open-source forge software package for hosting software development version control using Git as well as other collaborative features like bug tracking, wikis, and code review.\nFor more information please visit: gitea.io\nJupyterHub Gitea is an open-source forge software package for hosting software development version control using Git as well as other collaborative features like bug tracking, wikis, and code review.\nFor more information please visit: Jupyter Hub\nVS Code Visual Studio Code is a lightweight but powerful online code editor that support Python, Go, JavaScript, TypeScript, Node.js, etc) For more information please visit: VS Code\nDrone.io Drone.io is an open-source continuous integration platform built on Docker which allows automating Software Testing and Delivery.\nFor more information please visit: Drone.io\nMLFlow MLflow is an open-source platform to manage the ML lifecycle, including experimentation, reproducibility, and deployment. MLFlow allows tracking the results of jobs that have been scheduled in a pipeline. It is integrated with Minio for persistence.\nFor more information please visit: MLFlow\nPostgres Postgres is an open-source relational database management system emphasizing extensibility and technical standards compliance. It is designed to handle a range of workloads, from single machines to data warehouses or Web services with many concurrent users.\nFor more information please visit: PostgreSQL\n","excerpt":"Gitea Gitea is an open-source forge software package for hosting software development version …","ref":"/science-toolkit/docs/components/","title":"Components"},{"body":" Here is the detailed installation instructions for differente flavors of Kubernetes, like GKE, EKS or AKS.\n ","excerpt":" Here is the detailed installation instructions for differente flavors of Kubernetes, like GKE, EKS …","ref":"/science-toolkit/docs/installation/","title":"Installation"},{"body":" Here is the guidelines to contribute to this open source project.\n ","excerpt":" Here is the guidelines to contribute to this open source project.\n ","ref":"/science-toolkit/docs/contribution-guidelines/","title":"Contribution Guidelines"},{"body":"","excerpt":"","ref":"/science-toolkit/index.json","title":""},{"body":"  #td-cover-block-0 { background-image: url(/science-toolkit/about/featured-background_hu8a944d267ae3eda7658be2b204e4ea37_687139_960x540_fill_q75_catmullrom_bottom.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/science-toolkit/about/featured-background_hu8a944d267ae3eda7658be2b204e4ea37_687139_1920x1080_fill_q75_catmullrom_bottom.jpg); } }  About Science Toolkits An Open Source project to help Data Scientists        Science Toolkit is a solution that offers a standard environment to cover the technological and methodological needs of a data team working in any artificial intelligence project.     This is another section     ","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/science-toolkit/about/","title":"About Science Toolkits"},{"body":"","excerpt":"","ref":"/science-toolkit/community/","title":"Community"},{"body":"  #td-cover-block-0 { background-image: url(/science-toolkit/featured-background_hu8a944d267ae3eda7658be2b204e4ea37_687139_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/science-toolkit/featured-background_hu8a944d267ae3eda7658be2b204e4ea37_687139_1920x1080_fill_q75_catmullrom_top.jpg); } }  Welcome to Science Toolkit: An Open Source project to help Data Scientists! Learn More   Download   Porridge temperature assessment - in the cloud!\n\n        Science Toolkits is an open source project to help Data Scientist.    ","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/science-toolkit/","title":"Science Toolkits"},{"body":"","excerpt":"","ref":"/science-toolkit/search/","title":"Search Results"}]